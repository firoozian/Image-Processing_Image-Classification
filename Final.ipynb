{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba70bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from pathlib import Path as path\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Directory containing the dataset\n",
    "data_dir = 'C:/Users/Asus/Downloads/Tensor/New folder/seg_train/seg_train'\n",
    "save_dir = 'C:/Users/Asus/Downloads/Tensor/New folder/Predicted_Images'  # Directory to save correctly predicted images\n",
    "\n",
    "# Define parameters for image size and batch size\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator to load images in batches and split dataset\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,           # Normalize pixel values to [0, 1]\n",
    "    validation_split=0.2      # Reserve 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=None  # Set seed to None for better randomness\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "data_dir: The path to the directory where the images are stored.\n",
    "\n",
    "target_size=(img_height, img_width): The images are resized to the dimensions defined earlier, i.e., 180x180 pixels.\n",
    "\n",
    "batch_size=batch_size: Specifies the number of images to be processed in each batch. Here, it’s set to 32, so the model will process 32 images in each iteration.\n",
    "\n",
    "class_mode='sparse': This means the labels are encoded as integers instead of one-hot encoding. This is useful when you have multi-class classification, and the labels are in integer form, making it more memory-efficient. Each image will be assigned an integer representing its class.\n",
    "\n",
    "subset='training': Refers to the 80% portion of the dataset that is used for training, as set by the validation_split=0.2 earlier in the ImageDataGenerator.\n",
    "\n",
    "shuffle=True: Ensures that the data is shuffled after every epoch. This helps prevent the model from learning in sequence, which could lead to overfitting.\n",
    "\n",
    "seed=None: No specific seed is set for random number generation. This allows for better randomness when shuffling the dataset during training.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=1,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=None  # Set seed to None for better randomness\n",
    ")\n",
    "\n",
    "\"\"\"batch_size=1: For validation, \n",
    "the batch size is set to 1. \n",
    "This means each image is evaluated individually. \n",
    "Validation typically doesn’t require large batch sizes since we are not training the model but only evaluating it.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Define class names\n",
    "class_names = {\n",
    "    0: 'building',\n",
    "    1: 'forest',\n",
    "    2: 'glacier',\n",
    "    3: 'mountain',\n",
    "    4: 'sea',\n",
    "    5: 'street'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "This is a dictionary that maps the integer class labels (0, 1, 2, 3, 4, 5) to their corresponding category names.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Retrieve a truly random batch of images and labels\n",
    "X_train_scaled, y_train = next(train_generator)  # Get the next batch of images and labels\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The train_generator is an iterator that loads batches of images and labels on the fly. This line retrieves the next batch of images and corresponding labels.\n",
    "X_train_scaled: This variable stores the batch of images that have been loaded and preprocessed (rescaled and resized). Each image has been normalized (pixel values scaled to [0, 1]).\n",
    "y_train: This contains the labels (class IDs) associated with the images in the batch.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Randomly select an index from the batch\n",
    "index_to_display = np.random.randint(len(X_train_scaled))\n",
    "random_image = X_train_scaled[index_to_display]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This generates a random integer between 0 and the length of X_train_scaled (which equals the batch size, i.e., 32). This random integer represents the index of a randomly chosen image within the batch.\n",
    "For example, if the batch has 32 images, this function could generate a random number from 0 to 31, allowing you to randomly select an image.\n",
    "\n",
    "Once the random index is selected, this line extracts the corresponding image (random_image) from the batch X_train_scaled.\n",
    "This image will be used for visualization or further processing.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Display the random image\n",
    "plt.imshow(random_image)\n",
    "plt.title(f'Class: {class_names[int(y_train[index_to_display])]}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "The title for the displayed image is set using the class name.\n",
    "\n",
    "y_train[index_to_display]: This retrieves the class label (an integer) of the random_image from the corresponding y_train array.\n",
    "\n",
    "int(y_train[index_to_display]): Converts the label to an integer, as y_train might store the labels in float format due to preprocessing.\n",
    "\n",
    "class_names[...]: This dictionary is used to convert the integer label into a human-readable class name (e.g., 'forest', 'sea', etc.).\n",
    "\n",
    "The f'...' format string ensures the class name is dynamically added to the title.\n",
    "\n",
    "plt.axis('off'):\n",
    "\n",
    "This removes the axis around the image (x and y coordinates), so only the image is displayed without any borders, ticks, or labels.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Print the scaled pixel values of the image\n",
    "print(f'Scaled pixel values of the image')\n",
    "print(random_image)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "# CNN model building\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),  # Convolutional layer\n",
    "    layers.MaxPooling2D(2, 2),  # Pooling layer\n",
    "    layers.Dropout(0.25),  # Dropout layer\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    Conv2D Layer: This is a 2D convolutional layer that learns filters/kernels, which are applied to the input images.\n",
    "filters=32: The layer uses 32 filters, meaning it will produce 32 different feature maps. \n",
    "Filters help detect features like edges, textures, and patterns.(The numbers 32, 64, and 128 are Powers of two are commonly used because they are efficient for computation on digital hardware, such as GPUs, due to their binary nature. This choice makes memory allocation, parallelism, and processing faster and more efficient.)\n",
    "kernel_size=(3, 3): This is the size of each filter. A 3x3 filter moves over the image and learns spatial patterns.\n",
    "activation='relu': The ReLU (Rectified Linear Unit) activation function is applied to the output of the convolution to introduce non-linearity. \n",
    "It replaces negative values with 0, keeping only positive values.\n",
    "\n",
    "MaxPooling2D(2, 2): This is a pooling layer that reduces the spatial dimensions (height and width) of the feature maps.\n",
    "It takes a 2x2 block of pixels and selects the maximum value, hence the name \"max pooling.\"\n",
    "Purpose: This layer down-samples the feature maps, reducing computational load, preventing overfitting, and retaining only the most important information.\n",
    "\n",
    "\n",
    "Dropout(0.25): Dropout is a regularization technique that randomly drops (sets to zero) 25% of the neurons in the layer during each training step.\n",
    "Purpose: Prevents overfitting by ensuring that the model does not rely too heavily on specific neurons and instead learns more generalized features.\n",
    "\n",
    "\n",
    "\"\"\"    \n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),  # Convolutional layer\n",
    "    layers.MaxPooling2D(2, 2),  # Pooling layer\n",
    "    layers.Dropout(0.25),  # Dropout layer\n",
    "\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),  # Convolutional layer\n",
    "    layers.MaxPooling2D(2, 2),  # Pooling layer\n",
    "    layers.Dropout(0.25),  # Dropout layer\n",
    "\n",
    "    layers.Flatten(),  # Flatten layer\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer\n",
    "    layers.Dropout(0.5),  # Dropout layer\n",
    "    layers.Dense(num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "Flatten(): Converts the 2D feature maps output from the last pooling layer into a 1D vector. \n",
    "This is necessary because fully connected layers (Dense layers) expect 1D input.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model.summary() # summary of the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,  # Training data generator\n",
    "    epochs=20,  # Number of epochs to train the model\n",
    "    validation_data=validation_generator,  # Validation data generator\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # Number of batches per epoch\n",
    "    validation_steps=validation_generator.samples // batch_size  # Number of batches in validation\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Make predictions on a random batch from the validation set\n",
    "X_val_scaled, y_val = next(validation_generator)  # Get a batch of validation data\n",
    "\n",
    "# Predict the classes for the batch\n",
    "predictions = model.predict(X_val_scaled)\n",
    "\n",
    "# Randomly select an index from the batch for visualization\n",
    "index_to_display = np.random.randint(len(X_val_scaled))\n",
    "\n",
    "# Get the predicted class for the selected sample\n",
    "predicted_class = np.argmax(predictions[index_to_display])\n",
    "\n",
    "# Get the true class for the selected sample\n",
    "true_class = int(y_val[index_to_display])  # Convert to integer if needed\n",
    "\n",
    "# Display the selected image with the predicted and true classes\n",
    "plt.imshow(X_val_scaled[index_to_display])\n",
    "plt.title(f'Predicted Class: {class_names[predicted_class]}, True Class: {class_names[true_class]}')\n",
    "plt.axis('off')  # Hide the axes\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print the result of the prediction\n",
    "if predicted_class == true_class:\n",
    "    print(f'Correct prediction! Predicted: {class_names[predicted_class]}, True: {class_names[true_class]}')\n",
    "else:\n",
    "    print(f'Incorrect prediction. Predicted: {class_names[predicted_class]}, True: {class_names[true_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final step to evaluate the model on the test data and save the predicted images along with their classified labels in the appropriate directories\n",
    "test_dir = 'C:/Users/Asus/Downloads/Tensor/New folder/seg_test/'\n",
    "save_dir = 'C:/Users/Asus/Downloads/Tensor/New folder/Predicted_Images'  # Directory to save correctly predicted images\n",
    "\n",
    "# Create directories for each class inside the save_dir\n",
    "for class_name in class_names.values():\n",
    "    os.makedirs(os.path.join(save_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Use ImageDataGenerator for the test set (without validation split)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=1,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False  # No shuffling so that results are consistent with file order\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Predict on the test set\n",
    "test_generator.reset()  # Reset the generator to avoid any side effects\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Iterate over each image in the test set\n",
    "for i in range(len(predictions)):\n",
    "    predicted_class = np.argmax(predictions[i])  # Get predicted class index\n",
    "    true_class = int(test_generator.labels[i])  # Get true class index\n",
    "\n",
    "    # Get the file path of the current image\n",
    "    img_path = test_generator.filepaths[i]\n",
    "    img_name = os.path.basename(img_path)\n",
    "\n",
    "    # Load the image (optional, for display or saving later)\n",
    "    img = PIL.Image.open(img_path)\n",
    "\n",
    "    # Print prediction result\n",
    "    if predicted_class == true_class:\n",
    "        print(f'Correctly predicted: {class_names[predicted_class]} for image {img_name}')\n",
    "    else:\n",
    "        print(f'Incorrectly predicted: {class_names[predicted_class]} (True: {class_names[true_class]}) for image {img_name}')\n",
    "\n",
    "    # Save the image to the predicted class directory\n",
    "    save_path = os.path.join(save_dir, class_names[predicted_class], img_name)\n",
    "    img.save(save_path)\n",
    "\n",
    "print(f'All predicted images saved to {save_dir}.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
